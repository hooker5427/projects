{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from  sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble  import GradientBoostingClassifier \n",
    "from lightgbm import LGBMClassifier \n",
    "from  sklearn.model_selection import  train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./preprocesss_train_test_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(data) -2968\n",
    "train_data   = data.iloc[ 0:train_size , :]\n",
    "test_data = data.iloc[train_size: ,: ] \n",
    "train_data = train_data.drop( ['id'] ,axis =1   )\n",
    "\n",
    "test_sub= test_data.loc[ :, ['id']]\n",
    "test_data  = test_data.drop( ['id' , 'happiness' ] ,axis =1   ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train ,x_train =  train_data['happiness'] ,train_data.drop( 'happiness' ,axis =1 )\n",
    "x_test = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train =y_train.astype('int64') -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 133) (1600, 133) (6400,) (1600,)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_valid, Y,Y_valid = train_test_split(x_train , \n",
    "                                              y_train ,\n",
    "                                              test_size = 0.2 ,\n",
    "                                              random_state  = 17  )\n",
    "print (X_train.shape , X_valid.shape , Y.shape , Y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's l2: 0.29796\tvalid_1's l2: 0.339481\n",
      "[400]\ttraining's l2: 0.254405\tvalid_1's l2: 0.327559\n",
      "[600]\ttraining's l2: 0.227084\tvalid_1's l2: 0.324552\n",
      "[800]\ttraining's l2: 0.204546\tvalid_1's l2: 0.323406\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's l2: 0.21125\tvalid_1's l2: 0.32323\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's l2: 0.291468\tvalid_1's l2: 0.35907\n",
      "[400]\ttraining's l2: 0.247803\tvalid_1's l2: 0.352483\n",
      "Early stopping, best iteration is:\n",
      "[450]\ttraining's l2: 0.239672\tvalid_1's l2: 0.352289\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's l2: 0.291424\tvalid_1's l2: 0.365961\n",
      "[400]\ttraining's l2: 0.249339\tvalid_1's l2: 0.354856\n",
      "[600]\ttraining's l2: 0.221037\tvalid_1's l2: 0.353298\n",
      "Early stopping, best iteration is:\n",
      "[629]\ttraining's l2: 0.217623\tvalid_1's l2: 0.353064\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's l2: 0.30067\tvalid_1's l2: 0.323725\n",
      "[400]\ttraining's l2: 0.256819\tvalid_1's l2: 0.318435\n",
      "[600]\ttraining's l2: 0.228145\tvalid_1's l2: 0.31826\n",
      "Early stopping, best iteration is:\n",
      "[526]\ttraining's l2: 0.23754\tvalid_1's l2: 0.318174\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's l2: 0.295148\tvalid_1's l2: 0.351144\n",
      "[400]\ttraining's l2: 0.25208\tvalid_1's l2: 0.342875\n",
      "[600]\ttraining's l2: 0.224422\tvalid_1's l2: 0.340253\n",
      "[800]\ttraining's l2: 0.202245\tvalid_1's l2: 0.338795\n",
      "[1000]\ttraining's l2: 0.183458\tvalid_1's l2: 0.338086\n",
      "Early stopping, best iteration is:\n",
      "[938]\ttraining's l2: 0.188872\tvalid_1's l2: 0.337852\n",
      "CV score: 0.33692201\n"
     ]
    }
   ],
   "source": [
    "##### lgb\n",
    "from  sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "param = {'boosting_type': 'gbdt',\n",
    "         'num_leaves': 20,\n",
    "         'min_data_in_leaf': 20, \n",
    "         'objective':'regression',\n",
    "         'max_depth':6,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 30,\n",
    "\n",
    "         \"feature_fraction\": 0.8,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.8 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'mse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1}\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_lgb = np.zeros(len(X_train))\n",
    "predictions_lgb = np.zeros(len(x_test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, Y)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(X_train.iloc[trn_idx],  Y.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train.iloc[val_idx],  Y.iloc[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data,\n",
    "                    num_round, \n",
    "                    valid_sets = [trn_data, val_data], \n",
    "                    verbose_eval=200, \n",
    "                    early_stopping_rounds = 100)\n",
    "    oof_lgb[val_idx] = clf.predict(X_train.iloc[val_idx], \n",
    "                                   num_iteration=clf.best_iteration)\n",
    "\n",
    "    predictions_lgb += clf.predict(x_test, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb, Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[0]\ttrain-rmse:2.47777\tvalid_data-rmse:2.50704\ttrain-myFeval:6.13937\tvalid_data-myFeval:6.28524\n",
      "Multiple eval metrics have been passed: 'valid_data-myFeval' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-myFeval hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:1.57189\tvalid_data-rmse:1.60494\ttrain-myFeval:2.47083\tvalid_data-myFeval:2.57584\n",
      "[200]\ttrain-rmse:1.05120\tvalid_data-rmse:1.09122\ttrain-myFeval:1.10501\tvalid_data-myFeval:1.19076\n",
      "[300]\ttrain-rmse:0.76799\tvalid_data-rmse:0.81751\ttrain-myFeval:0.58980\tvalid_data-myFeval:0.66832\n",
      "[400]\ttrain-rmse:0.62386\tvalid_data-rmse:0.68400\ttrain-myFeval:0.38920\tvalid_data-myFeval:0.46786\n",
      "[500]\ttrain-rmse:0.55373\tvalid_data-rmse:0.62376\ttrain-myFeval:0.30662\tvalid_data-myFeval:0.38908\n",
      "[600]\ttrain-rmse:0.51881\tvalid_data-rmse:0.59768\ttrain-myFeval:0.26916\tvalid_data-myFeval:0.35722\n",
      "[700]\ttrain-rmse:0.49928\tvalid_data-rmse:0.58591\ttrain-myFeval:0.24928\tvalid_data-myFeval:0.34329\n",
      "[800]\ttrain-rmse:0.48610\tvalid_data-rmse:0.58012\ttrain-myFeval:0.23630\tvalid_data-myFeval:0.33654\n",
      "[900]\ttrain-rmse:0.47565\tvalid_data-rmse:0.57717\ttrain-myFeval:0.22625\tvalid_data-myFeval:0.33312\n",
      "[1000]\ttrain-rmse:0.46696\tvalid_data-rmse:0.57546\ttrain-myFeval:0.21805\tvalid_data-myFeval:0.33115\n",
      "[1100]\ttrain-rmse:0.45885\tvalid_data-rmse:0.57437\ttrain-myFeval:0.21054\tvalid_data-myFeval:0.32990\n",
      "[1200]\ttrain-rmse:0.45157\tvalid_data-rmse:0.57345\ttrain-myFeval:0.20392\tvalid_data-myFeval:0.32884\n",
      "[1300]\ttrain-rmse:0.44423\tvalid_data-rmse:0.57286\ttrain-myFeval:0.19734\tvalid_data-myFeval:0.32816\n",
      "[1400]\ttrain-rmse:0.43746\tvalid_data-rmse:0.57220\ttrain-myFeval:0.19137\tvalid_data-myFeval:0.32742\n",
      "[1500]\ttrain-rmse:0.43072\tvalid_data-rmse:0.57188\ttrain-myFeval:0.18552\tvalid_data-myFeval:0.32705\n",
      "[1600]\ttrain-rmse:0.42406\tvalid_data-rmse:0.57154\ttrain-myFeval:0.17983\tvalid_data-myFeval:0.32666\n",
      "[1700]\ttrain-rmse:0.41757\tvalid_data-rmse:0.57162\ttrain-myFeval:0.17436\tvalid_data-myFeval:0.32675\n",
      "[1800]\ttrain-rmse:0.41145\tvalid_data-rmse:0.57152\ttrain-myFeval:0.16929\tvalid_data-myFeval:0.32664\n",
      "[1900]\ttrain-rmse:0.40542\tvalid_data-rmse:0.57132\ttrain-myFeval:0.16437\tvalid_data-myFeval:0.32641\n",
      "[2000]\ttrain-rmse:0.39941\tvalid_data-rmse:0.57134\ttrain-myFeval:0.15952\tvalid_data-myFeval:0.32643\n",
      "[2100]\ttrain-rmse:0.39353\tvalid_data-rmse:0.57131\ttrain-myFeval:0.15487\tvalid_data-myFeval:0.32639\n",
      "[2200]\ttrain-rmse:0.38786\tvalid_data-rmse:0.57103\ttrain-myFeval:0.15044\tvalid_data-myFeval:0.32608\n",
      "[2300]\ttrain-rmse:0.38228\tvalid_data-rmse:0.57114\ttrain-myFeval:0.14614\tvalid_data-myFeval:0.32620\n",
      "[2400]\ttrain-rmse:0.37709\tvalid_data-rmse:0.57114\ttrain-myFeval:0.14220\tvalid_data-myFeval:0.32620\n",
      "Stopping. Best iteration:\n",
      "[2263]\ttrain-rmse:0.38432\tvalid_data-rmse:0.57096\ttrain-myFeval:0.14771\tvalid_data-myFeval:0.32599\n",
      "\n",
      "fold n°2\n",
      "[0]\ttrain-rmse:2.48395\tvalid_data-rmse:2.48207\ttrain-myFeval:6.17003\tvalid_data-myFeval:6.16069\n",
      "Multiple eval metrics have been passed: 'valid_data-myFeval' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-myFeval hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:1.57485\tvalid_data-rmse:1.58416\ttrain-myFeval:2.48014\tvalid_data-myFeval:2.50956\n",
      "[200]\ttrain-rmse:1.05087\tvalid_data-rmse:1.07659\ttrain-myFeval:1.10434\tvalid_data-myFeval:1.15905\n",
      "[300]\ttrain-rmse:0.76504\tvalid_data-rmse:0.81101\ttrain-myFeval:0.58529\tvalid_data-myFeval:0.65774\n",
      "[400]\ttrain-rmse:0.61955\tvalid_data-rmse:0.68616\ttrain-myFeval:0.38384\tvalid_data-myFeval:0.47081\n",
      "[500]\ttrain-rmse:0.54888\tvalid_data-rmse:0.63209\ttrain-myFeval:0.30126\tvalid_data-myFeval:0.39954\n",
      "[600]\ttrain-rmse:0.51354\tvalid_data-rmse:0.60994\ttrain-myFeval:0.26373\tvalid_data-myFeval:0.37202\n",
      "[700]\ttrain-rmse:0.49311\tvalid_data-rmse:0.60071\ttrain-myFeval:0.24316\tvalid_data-myFeval:0.36085\n",
      "[800]\ttrain-rmse:0.47968\tvalid_data-rmse:0.59676\ttrain-myFeval:0.23009\tvalid_data-myFeval:0.35613\n",
      "[900]\ttrain-rmse:0.46921\tvalid_data-rmse:0.59498\ttrain-myFeval:0.22016\tvalid_data-myFeval:0.35400\n",
      "[1000]\ttrain-rmse:0.46038\tvalid_data-rmse:0.59403\ttrain-myFeval:0.21195\tvalid_data-myFeval:0.35287\n",
      "[1100]\ttrain-rmse:0.45191\tvalid_data-rmse:0.59359\ttrain-myFeval:0.20422\tvalid_data-myFeval:0.35235\n",
      "[1200]\ttrain-rmse:0.44451\tvalid_data-rmse:0.59337\ttrain-myFeval:0.19759\tvalid_data-myFeval:0.35209\n",
      "[1300]\ttrain-rmse:0.43724\tvalid_data-rmse:0.59357\ttrain-myFeval:0.19118\tvalid_data-myFeval:0.35233\n",
      "[1400]\ttrain-rmse:0.42999\tvalid_data-rmse:0.59371\ttrain-myFeval:0.18490\tvalid_data-myFeval:0.35249\n",
      "Stopping. Best iteration:\n",
      "[1221]\ttrain-rmse:0.44299\tvalid_data-rmse:0.59333\ttrain-myFeval:0.19624\tvalid_data-myFeval:0.35204\n",
      "\n",
      "fold n°3\n",
      "[0]\ttrain-rmse:2.48675\tvalid_data-rmse:2.47069\ttrain-myFeval:6.18391\tvalid_data-myFeval:6.10430\n",
      "Multiple eval metrics have been passed: 'valid_data-myFeval' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-myFeval hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:1.57590\tvalid_data-rmse:1.57118\ttrain-myFeval:2.48344\tvalid_data-myFeval:2.46861\n",
      "[200]\ttrain-rmse:1.05234\tvalid_data-rmse:1.06518\ttrain-myFeval:1.10742\tvalid_data-myFeval:1.13461\n",
      "[300]\ttrain-rmse:0.76721\tvalid_data-rmse:0.80281\ttrain-myFeval:0.58861\tvalid_data-myFeval:0.64451\n",
      "[400]\ttrain-rmse:0.62223\tvalid_data-rmse:0.68136\ttrain-myFeval:0.38718\tvalid_data-myFeval:0.46425\n",
      "[500]\ttrain-rmse:0.55197\tvalid_data-rmse:0.63071\ttrain-myFeval:0.30467\tvalid_data-myFeval:0.39780\n",
      "[600]\ttrain-rmse:0.51680\tvalid_data-rmse:0.61085\ttrain-myFeval:0.26708\tvalid_data-myFeval:0.37313\n",
      "[700]\ttrain-rmse:0.49713\tvalid_data-rmse:0.60355\ttrain-myFeval:0.24714\tvalid_data-myFeval:0.36427\n",
      "[800]\ttrain-rmse:0.48383\tvalid_data-rmse:0.60091\ttrain-myFeval:0.23409\tvalid_data-myFeval:0.36110\n",
      "[900]\ttrain-rmse:0.47346\tvalid_data-rmse:0.59964\ttrain-myFeval:0.22416\tvalid_data-myFeval:0.35957\n",
      "[1000]\ttrain-rmse:0.46470\tvalid_data-rmse:0.59908\ttrain-myFeval:0.21594\tvalid_data-myFeval:0.35890\n",
      "[1100]\ttrain-rmse:0.45649\tvalid_data-rmse:0.59877\ttrain-myFeval:0.20838\tvalid_data-myFeval:0.35853\n",
      "[1200]\ttrain-rmse:0.44892\tvalid_data-rmse:0.59861\ttrain-myFeval:0.20153\tvalid_data-myFeval:0.35833\n",
      "[1300]\ttrain-rmse:0.44170\tvalid_data-rmse:0.59835\ttrain-myFeval:0.19510\tvalid_data-myFeval:0.35802\n",
      "[1400]\ttrain-rmse:0.43443\tvalid_data-rmse:0.59812\ttrain-myFeval:0.18873\tvalid_data-myFeval:0.35775\n",
      "[1500]\ttrain-rmse:0.42756\tvalid_data-rmse:0.59844\ttrain-myFeval:0.18280\tvalid_data-myFeval:0.35813\n",
      "[1600]\ttrain-rmse:0.42079\tvalid_data-rmse:0.59874\ttrain-myFeval:0.17707\tvalid_data-myFeval:0.35849\n",
      "Stopping. Best iteration:\n",
      "[1409]\ttrain-rmse:0.43377\tvalid_data-rmse:0.59806\ttrain-myFeval:0.18816\tvalid_data-myFeval:0.35768\n",
      "\n",
      "fold n°4\n",
      "[0]\ttrain-rmse:2.48650\tvalid_data-rmse:2.47200\ttrain-myFeval:6.18268\tvalid_data-myFeval:6.11079\n",
      "Multiple eval metrics have been passed: 'valid_data-myFeval' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-myFeval hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:1.57796\tvalid_data-rmse:1.56582\ttrain-myFeval:2.48997\tvalid_data-myFeval:2.45179\n",
      "[200]\ttrain-rmse:1.05568\tvalid_data-rmse:1.05106\ttrain-myFeval:1.11447\tvalid_data-myFeval:1.10473\n",
      "[300]\ttrain-rmse:0.77106\tvalid_data-rmse:0.77973\ttrain-myFeval:0.59453\tvalid_data-myFeval:0.60797\n",
      "[400]\ttrain-rmse:0.62672\tvalid_data-rmse:0.65090\ttrain-myFeval:0.39277\tvalid_data-myFeval:0.42367\n",
      "[500]\ttrain-rmse:0.55684\tvalid_data-rmse:0.59581\ttrain-myFeval:0.31007\tvalid_data-myFeval:0.35499\n",
      "[600]\ttrain-rmse:0.52166\tvalid_data-rmse:0.57430\ttrain-myFeval:0.27213\tvalid_data-myFeval:0.32982\n",
      "[700]\ttrain-rmse:0.50192\tvalid_data-rmse:0.56603\ttrain-myFeval:0.25193\tvalid_data-myFeval:0.32039\n",
      "[800]\ttrain-rmse:0.48905\tvalid_data-rmse:0.56281\ttrain-myFeval:0.23917\tvalid_data-myFeval:0.31675\n",
      "[900]\ttrain-rmse:0.47864\tvalid_data-rmse:0.56187\ttrain-myFeval:0.22909\tvalid_data-myFeval:0.31569\n",
      "[1000]\ttrain-rmse:0.47013\tvalid_data-rmse:0.56126\ttrain-myFeval:0.22102\tvalid_data-myFeval:0.31502\n",
      "[1100]\ttrain-rmse:0.46198\tvalid_data-rmse:0.56111\ttrain-myFeval:0.21342\tvalid_data-myFeval:0.31484\n",
      "[1200]\ttrain-rmse:0.45434\tvalid_data-rmse:0.56090\ttrain-myFeval:0.20642\tvalid_data-myFeval:0.31461\n",
      "[1300]\ttrain-rmse:0.44705\tvalid_data-rmse:0.56100\ttrain-myFeval:0.19985\tvalid_data-myFeval:0.31472\n",
      "[1400]\ttrain-rmse:0.43974\tvalid_data-rmse:0.56102\ttrain-myFeval:0.19337\tvalid_data-myFeval:0.31475\n",
      "Stopping. Best iteration:\n",
      "[1206]\ttrain-rmse:0.45402\tvalid_data-rmse:0.56080\ttrain-myFeval:0.20613\tvalid_data-myFeval:0.31449\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°5\n",
      "[0]\ttrain-rmse:2.48298\tvalid_data-rmse:2.48611\ttrain-myFeval:6.16520\tvalid_data-myFeval:6.18077\n",
      "Multiple eval metrics have been passed: 'valid_data-myFeval' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-myFeval hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:1.57431\tvalid_data-rmse:1.58490\ttrain-myFeval:2.47846\tvalid_data-myFeval:2.51190\n",
      "[200]\ttrain-rmse:1.05128\tvalid_data-rmse:1.07444\ttrain-myFeval:1.10519\tvalid_data-myFeval:1.15442\n",
      "[300]\ttrain-rmse:0.76677\tvalid_data-rmse:0.80666\ttrain-myFeval:0.58794\tvalid_data-myFeval:0.65070\n",
      "[400]\ttrain-rmse:0.62218\tvalid_data-rmse:0.67989\ttrain-myFeval:0.38711\tvalid_data-myFeval:0.46226\n",
      "[500]\ttrain-rmse:0.55226\tvalid_data-rmse:0.62495\ttrain-myFeval:0.30500\tvalid_data-myFeval:0.39056\n",
      "[600]\ttrain-rmse:0.51726\tvalid_data-rmse:0.60260\ttrain-myFeval:0.26756\tvalid_data-myFeval:0.36312\n",
      "[700]\ttrain-rmse:0.49773\tvalid_data-rmse:0.59301\ttrain-myFeval:0.24774\tvalid_data-myFeval:0.35166\n",
      "[800]\ttrain-rmse:0.48456\tvalid_data-rmse:0.58884\ttrain-myFeval:0.23480\tvalid_data-myFeval:0.34673\n",
      "[900]\ttrain-rmse:0.47434\tvalid_data-rmse:0.58647\ttrain-myFeval:0.22500\tvalid_data-myFeval:0.34394\n",
      "[1000]\ttrain-rmse:0.46541\tvalid_data-rmse:0.58543\ttrain-myFeval:0.21660\tvalid_data-myFeval:0.34273\n",
      "[1100]\ttrain-rmse:0.45720\tvalid_data-rmse:0.58472\ttrain-myFeval:0.20903\tvalid_data-myFeval:0.34189\n",
      "[1200]\ttrain-rmse:0.44971\tvalid_data-rmse:0.58417\ttrain-myFeval:0.20224\tvalid_data-myFeval:0.34125\n",
      "[1300]\ttrain-rmse:0.44248\tvalid_data-rmse:0.58371\ttrain-myFeval:0.19579\tvalid_data-myFeval:0.34072\n",
      "[1400]\ttrain-rmse:0.43550\tvalid_data-rmse:0.58348\ttrain-myFeval:0.18966\tvalid_data-myFeval:0.34044\n",
      "[1500]\ttrain-rmse:0.42871\tvalid_data-rmse:0.58281\ttrain-myFeval:0.18379\tvalid_data-myFeval:0.33966\n",
      "[1600]\ttrain-rmse:0.42215\tvalid_data-rmse:0.58240\ttrain-myFeval:0.17821\tvalid_data-myFeval:0.33919\n",
      "[1700]\ttrain-rmse:0.41576\tvalid_data-rmse:0.58243\ttrain-myFeval:0.17285\tvalid_data-myFeval:0.33922\n",
      "[1800]\ttrain-rmse:0.40958\tvalid_data-rmse:0.58212\ttrain-myFeval:0.16775\tvalid_data-myFeval:0.33886\n",
      "[1900]\ttrain-rmse:0.40376\tvalid_data-rmse:0.58202\ttrain-myFeval:0.16303\tvalid_data-myFeval:0.33875\n",
      "[2000]\ttrain-rmse:0.39783\tvalid_data-rmse:0.58164\ttrain-myFeval:0.15827\tvalid_data-myFeval:0.33830\n",
      "[2100]\ttrain-rmse:0.39190\tvalid_data-rmse:0.58144\ttrain-myFeval:0.15359\tvalid_data-myFeval:0.33807\n",
      "[2200]\ttrain-rmse:0.38642\tvalid_data-rmse:0.58144\ttrain-myFeval:0.14932\tvalid_data-myFeval:0.33808\n",
      "[2300]\ttrain-rmse:0.38125\tvalid_data-rmse:0.58121\ttrain-myFeval:0.14535\tvalid_data-myFeval:0.33780\n",
      "[2400]\ttrain-rmse:0.37590\tvalid_data-rmse:0.58098\ttrain-myFeval:0.14130\tvalid_data-myFeval:0.33754\n",
      "[2500]\ttrain-rmse:0.37064\tvalid_data-rmse:0.58077\ttrain-myFeval:0.13737\tvalid_data-myFeval:0.33729\n",
      "[2600]\ttrain-rmse:0.36560\tvalid_data-rmse:0.58075\ttrain-myFeval:0.13366\tvalid_data-myFeval:0.33727\n",
      "[2700]\ttrain-rmse:0.36068\tvalid_data-rmse:0.58071\ttrain-myFeval:0.13009\tvalid_data-myFeval:0.33722\n",
      "[2800]\ttrain-rmse:0.35578\tvalid_data-rmse:0.58055\ttrain-myFeval:0.12658\tvalid_data-myFeval:0.33704\n",
      "[2900]\ttrain-rmse:0.35064\tvalid_data-rmse:0.58040\ttrain-myFeval:0.12295\tvalid_data-myFeval:0.33687\n",
      "[3000]\ttrain-rmse:0.34588\tvalid_data-rmse:0.58021\ttrain-myFeval:0.11963\tvalid_data-myFeval:0.33664\n",
      "[3100]\ttrain-rmse:0.34103\tvalid_data-rmse:0.58011\ttrain-myFeval:0.11630\tvalid_data-myFeval:0.33653\n",
      "[3200]\ttrain-rmse:0.33638\tvalid_data-rmse:0.58001\ttrain-myFeval:0.11315\tvalid_data-myFeval:0.33642\n",
      "[3300]\ttrain-rmse:0.33187\tvalid_data-rmse:0.58000\ttrain-myFeval:0.11014\tvalid_data-myFeval:0.33640\n",
      "[3400]\ttrain-rmse:0.32774\tvalid_data-rmse:0.57981\ttrain-myFeval:0.10742\tvalid_data-myFeval:0.33618\n",
      "[3500]\ttrain-rmse:0.32369\tvalid_data-rmse:0.57971\ttrain-myFeval:0.10477\tvalid_data-myFeval:0.33606\n",
      "[3600]\ttrain-rmse:0.31925\tvalid_data-rmse:0.57952\ttrain-myFeval:0.10192\tvalid_data-myFeval:0.33584\n",
      "[3700]\ttrain-rmse:0.31483\tvalid_data-rmse:0.57954\ttrain-myFeval:0.09911\tvalid_data-myFeval:0.33587\n",
      "[3800]\ttrain-rmse:0.31067\tvalid_data-rmse:0.57942\ttrain-myFeval:0.09652\tvalid_data-myFeval:0.33573\n",
      "[3900]\ttrain-rmse:0.30654\tvalid_data-rmse:0.57927\ttrain-myFeval:0.09397\tvalid_data-myFeval:0.33556\n",
      "[4000]\ttrain-rmse:0.30244\tvalid_data-rmse:0.57930\ttrain-myFeval:0.09147\tvalid_data-myFeval:0.33558\n",
      "[4100]\ttrain-rmse:0.29836\tvalid_data-rmse:0.57929\ttrain-myFeval:0.08902\tvalid_data-myFeval:0.33558\n",
      "[4200]\ttrain-rmse:0.29422\tvalid_data-rmse:0.57915\ttrain-myFeval:0.08657\tvalid_data-myFeval:0.33542\n",
      "[4300]\ttrain-rmse:0.29019\tvalid_data-rmse:0.57925\ttrain-myFeval:0.08421\tvalid_data-myFeval:0.33553\n",
      "[4400]\ttrain-rmse:0.28653\tvalid_data-rmse:0.57931\ttrain-myFeval:0.08210\tvalid_data-myFeval:0.33560\n",
      "Stopping. Best iteration:\n",
      "[4204]\ttrain-rmse:0.29409\tvalid_data-rmse:0.57913\ttrain-myFeval:0.08649\tvalid_data-myFeval:0.33539\n",
      "\n",
      "CV score: 0.33711914\n"
     ]
    }
   ],
   "source": [
    "##### xgb\n",
    "import xgboost as xgb\n",
    "#自定义评价函数\n",
    "def msefunc(preds, xgbtrain):\n",
    "    label = xgbtrain.get_label()\n",
    "    score = mean_squared_error(label,preds)\n",
    "    return 'myFeval',score\n",
    "\n",
    "xgb_params = {\"booster\":'gbtree','eta': 0.005, 'max_depth': 5, 'subsample': 0.7, \n",
    "              'colsample_bytree': 0.8, 'objective': 'reg:linear', 'eval_metric': 'rmse', 'silent': True, 'nthread': 8}\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_xgb = np.zeros(len(X_train))\n",
    "predictions_xgb = np.zeros(len(x_test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, Y)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = xgb.DMatrix(X_train.iloc[trn_idx ,:], Y.iloc[trn_idx])\n",
    "    val_data = xgb.DMatrix(X_train.iloc[val_idx,: ], Y.iloc[val_idx])\n",
    "    \n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    clf = xgb.train(dtrain=trn_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=100, params=xgb_params,feval = msefunc)\n",
    "    oof_xgb[val_idx] = clf.predict(xgb.DMatrix(X_train.iloc[val_idx ,:]), ntree_limit=clf.best_ntree_limit)\n",
    "    predictions_xgb += clf.predict(xgb.DMatrix(x_test), ntree_limit=clf.best_ntree_limit) / folds.n_splits\n",
    "    \n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb, Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.33644929\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from  sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "# 将lgb和xgb和ctb的结果进行stacking\n",
    "train_stack =  pd.concat( [ pd.Series(oof_lgb ) ,pd.Series( oof_xgb ) ] ,axis =1 ) \n",
    "test_stack = pd.concat( [ pd.Series(predictions_lgb) ,\n",
    "                         pd.Series( predictions_xgb )  ] ,axis =1 ) \n",
    "\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=2018)\n",
    "oof_stack = np.zeros(train_stack.shape[0])\n",
    "predictions = np.zeros(test_stack.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack,Y)):\n",
    "    trn_data, trn_y = train_stack.iloc[ trn_idx,: ], Y.iloc[trn_idx ]\n",
    "    val_data, val_y = train_stack.iloc[ val_idx ,:  ], Y.iloc[val_idx]\n",
    "\n",
    "    clf_stack =linear_model.LinearRegression()\n",
    "    clf_stack.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack[val_idx] = clf_stack.predict(val_data)\n",
    "    predictions += clf_stack.predict(test_stack) / 10\n",
    "    \n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_stack, Y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=list(predictions)\n",
    "result=list(map(lambda x: x + 1, result))\n",
    "test_sub[\"happiness\"]=result\n",
    "test_sub.to_csv(\"submit_02.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>happiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8000</th>\n",
       "      <td>8001</td>\n",
       "      <td>3.899866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8001</th>\n",
       "      <td>8002</td>\n",
       "      <td>3.477392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8002</th>\n",
       "      <td>8003</td>\n",
       "      <td>3.439279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8003</th>\n",
       "      <td>8004</td>\n",
       "      <td>4.174374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8004</th>\n",
       "      <td>8005</td>\n",
       "      <td>3.671427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10963</th>\n",
       "      <td>10964</td>\n",
       "      <td>4.312923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10964</th>\n",
       "      <td>10965</td>\n",
       "      <td>3.689481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10965</th>\n",
       "      <td>10966</td>\n",
       "      <td>4.044440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10966</th>\n",
       "      <td>10967</td>\n",
       "      <td>3.913298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10967</th>\n",
       "      <td>10968</td>\n",
       "      <td>4.458628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2968 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  happiness\n",
       "8000    8001   3.899866\n",
       "8001    8002   3.477392\n",
       "8002    8003   3.439279\n",
       "8003    8004   4.174374\n",
       "8004    8005   3.671427\n",
       "...      ...        ...\n",
       "10963  10964   4.312923\n",
       "10964  10965   3.689481\n",
       "10965  10966   4.044440\n",
       "10966  10967   3.913298\n",
       "10967  10968   4.458628\n",
       "\n",
       "[2968 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10968"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2.1",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
